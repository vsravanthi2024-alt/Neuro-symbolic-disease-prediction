{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0a5d1-59f5-4265-a689-d5a1a845379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Understand neuro-symbolic nlp\n",
    "\n",
    "### Subtask:\n",
    "Briefly explain what neuro-symbolic NLP is and how it can be relevant to medical text analysis.\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "*   The initial error encountered was a `KeyboardInterrupt` during the file upload process, not a code logic error in the model training steps.\n",
    "*   Neuro-symbolic NLP combines neural networks (good for pattern recognition) and symbolic methods (good for explicit knowledge and reasoning).\n",
    "*   Neuro-symbolic approaches are relevant to medical text analysis by allowing the integration of structured medical knowledge (like ontologies and guidelines) with data-driven learning from unstructured text.\n",
    "*   Potential sources of symbolic medical knowledge include Medical Ontologies (SNOMED CT, MeSH, ICD), Symptom-Disease Relationship Databases, Clinical Practice Guidelines, Drug-Symptom/Disease Interactions Databases, and Anatomical/Physiological Knowledge.\n",
    "*   Conceptual methods for integrating neural and symbolic components in this context include post-processing/rule-based adjustment of neural predictions, augmenting neural features with symbolic features, and building hybrid architectures.\n",
    "\n",
    "### Insights or Next Steps\n",
    "\n",
    "*   To proceed with model development, the user needs to successfully upload the dataset by re-running the cell that previously failed due to `KeyboardInterrupt`.\n",
    "*   Implementing a full neuro-symbolic model would require accessing or building structured medical knowledge bases and potentially designing more complex model architectures than the basic TF-IDF/classifier approach.\n",
    "\n",
    "**1. Symbolic Knowledge Representation:**\n",
    "\n",
    "Your dataset contains `symptoms` and `clinical_notes`. We can think of symbolic knowledge as structured information about medical concepts. For this dataset, potential symbolic components include:\n",
    "\n",
    "*   **Symptom-Disease Relationships:** A knowledge base (even a simple dictionary or list) linking specific symptoms or keywords found in your data to medical conditions. For example, knowing that \"cough\" and \"wheezing\" are symptoms often associated with \"COPD\" or \"Asthma\".\n",
    "*   **Medical Terminology Mapping:** Mapping variations of symptom descriptions to standardized terms.\n",
    "*   **Simple Rules:** Defining basic rules based on co-occurring symptoms (e.g., IF \"fever\" AND \"chills\" THEN consider \"Malaria\").\n",
    "\n",
    "**2. Neural Model Component:**\n",
    "\n",
    "The existing code uses TF-IDF to vectorize the text data (`clinical_notes` or `symptoms`) and a classifier (like Naive Bayes, Decision Tree, etc.) to learn patterns and predict medical conditions. This part represents the \"neuro\" or pattern recognition component. It learns associations directly from the text data you provide.\n",
    "\n",
    "**3. Integration of Neural and Symbolic Components (Conceptual Methods):**\n",
    "\n",
    "Given the limitations of directly integrating large external medical knowledge bases in this environment, here are a few ways you could conceptually combine the neural and symbolic aspects for your dataset:\n",
    "\n",
    "*   **Post-processing with Symbolic Rules:**\n",
    "    *   Train your neural model (e.g., Naive Bayes on TF-IDF features) as you have done.\n",
    "    *   When the model makes a prediction for a new clinical note, extract the key symptoms or terms from that note.\n",
    "    *   Apply simple symbolic rules or look up symptom-disease associations in your defined symbolic knowledge base.\n",
    "    *   Use the results from the symbolic knowledge to potentially:\n",
    "        *   Increase confidence in the neural model's prediction if the symbolic evidence supports it.\n",
    "        *   Suggest alternative conditions if the symptoms strongly align with a different disease in the symbolic base, even if the neural model's probability was lower.\n",
    "        *   Flag predictions that contradict strong symbolic rules for human review.\n",
    "\n",
    "*   **Feature Augmentation:**\n",
    "    *   Before training your neural model, create new features based on your symbolic knowledge.\n",
    "    *   For each clinical note, count how many symptoms related to a specific medical condition (based on your symbolic knowledge) are present.\n",
    "    *   Append these \"symbolic features\" to your existing TF-IDF features.\n",
    "    *   Train your neural model on this combined feature set. This allows the model to directly use the structured medical information during learning.\n",
    "\n",
    "*   **Hybrid System (Conceptual Design):**\n",
    "    *   Imagine a system where the neural component provides an initial probability distribution over medical conditions based on the text.\n",
    "    *   A symbolic reasoning component then takes this distribution and the extracted symptoms/concepts as input.\n",
    "    *   Using its medical knowledge and rules, the symbolic component refines the probabilities or makes a final decision, potentially providing a more explainable output by highlighting which rules or knowledge snippets led to the conclusion.\n",
    "\n",
    "**Limitations and Practical Steps:**\n",
    "\n",
    "Full implementation of these hybrid approaches would require defining and populating the symbolic knowledge bases, which is a significant task.\n",
    "\n",
    "\n",
    "# Conceptual Explanation of Neuro-Symbolic Integration for Medical Condition Prediction\n",
    "\n",
    "print(\"\\n--- Conceptual Neuro-Symbolic Approach ---\")\n",
    "print(\"Given the dataset and the goal of predicting medical conditions from clinical notes (or symptoms), a neuro-symbolic approach could combine the pattern recognition strengths of a neural model with structured medical knowledge.\")\n",
    "\n",
    "print(\"\\n1. Symbolic Knowledge Representation:\")\n",
    "print(\"   - We identified potential sources like Medical Ontologies (SNOMED CT), Symptom-Disease Databases, and Clinical Guidelines.\")\n",
    "print(\"   - Conceptually, this knowledge could be represented as:\")\n",
    "print(\"     - A dictionary mapping standardized symptom terms to related medical conditions (e.g., {'fever': ['Infection', 'Influenza'], 'cough': ['COPD', 'Asthma', 'Infection']}).\")\n",
    "print(\"     - A simple rule base (e.g., IF symptoms contain 'chest pain' AND 'shortness of breath' THEN strongly consider 'Heart Disease').\")\n",
    "print(\"     - A simplified knowledge graph where nodes are medical concepts and edges represent relationships (e.g., 'fever' --has_symptom--> 'Influenza').\")\n",
    "\n",
    "print(\"\\n2. Neural Model Component:\")\n",
    "print(\"   - The existing approach using TF-IDF vectorization and a classifier (like Naive Bayes, Random Forest, etc.) serves as the neural-like component.\")\n",
    "print(\"   - It learns patterns directly from the text data.\")\n",
    "print(\"   - Input: TF-IDF vectorized clinical notes/symptoms.\")\n",
    "print(\"   - Output: Initial probability distribution or prediction for medical conditions.\")\n",
    "\n",
    "print(\"\\n3. Integration of Neural and Symbolic Components:\")\n",
    "print(\"   - **Method 1: Post-processing/Rule-based Adjustment:**\")\n",
    "print(\"     - Train the neural model on the TF-IDF features.\")\n",
    "print(\"     - For a new prediction, get the neural model's output (predicted class and probabilities).\")\n",
    "print(\"     - Apply symbolic rules based on the extracted symptoms/concepts from the new text.\")\n",
    "print(\"     - Example: If the neural model predicts 'Asthma' with 70% confidence, but a symbolic rule states 'IF patient reports 'wheezing' AND 'inhaler use' THEN strongly suggests 'Asthma'', this rule could potentially boost the confidence score or confirm the prediction.\")\n",
    "print(\"     - Example: If the neural model predicts 'Unknown' but symbolic knowledge links reported symptoms directly to 'Malaria', the symbolic knowledge could override the neural prediction or suggest 'Malaria' for further investigation.\")\n",
    "\n",
    "print(\"   - **Method 2: Feature Augmentation:**\")\n",
    "print(\"     - Extract symbolic features from the text using the knowledge base.\")\n",
    "print(\"     - Example: For a given clinical note, count how many symptoms mentioned are strongly associated with 'COPD' according to the symbolic knowledge.\")\n",
    "print(\"     - Combine these symbolic features with the neural features (e.g., append them to the TF-IDF vectors).\")\n",
    "print(\"     - Train a final classifier on this augmented feature set.\")\n",
    "\n",
    "print(\"   - **Method 3: Hybrid Architecture (More Complex):**\")\n",
    "print(\"     - Design a model where symbolic knowledge influences the neural network's internal processing.\")\n",
    "print(\"     - Example: Use graph embeddings from a medical knowledge graph as initial representations for concepts, which are then processed by a neural network.\")\n",
    "print(\"     - Example: Use symbolic rules to constrain the possible output space of the neural network.\")\n",
    "\n",
    "print(\"\\nLimitations in this Environment:\")\n",
    "print(\"Implementing a full neuro-symbolic model requires access to structured medical knowledge bases (ontologies, rule sets) and potentially more complex model architectures than easily built in a simple script.\")\n",
    "print(\"The examples above are conceptual demonstrations of how such integration *could* work.\")\n",
    "\n",
    "print(\"\\nTo proceed with the existing code, please re-run the cell that failed and successfully upload the dataset.\")\n",
    "\n",
    "# Note: No executable neuro-symbolic model code is provided due to the conceptual nature and environment limitations.\n",
    "# The focus here is on explaining the error and the conceptual application of neuro-symbolic NLP.\n",
    "\n",
    "\"\"\"## Conceptual Feature Augmentation with Symbolic Knowledge\n",
    "\n",
    "This section demonstrates how you could conceptually use a simple symbolic knowledge base to create new features for your dataset. These features could then be combined with your existing TF-IDF features to potentially improve your medical condition prediction model.\n",
    "\n",
    "**Note:** This is a conceptual example. A real-world application would require a more comprehensive and accurate medical knowledge base.\n",
    "\n",
    "# Task\n",
    "Combine the medical dataset (assuming it's available from previous steps) with emotional scores from \"emotional_scores.csv\" to predict the type of medical condition or disease using clinical notes and symptoms.\n",
    "\n",
    "## Load and preprocess emotional scores\n",
    "\n",
    "### Subtask:\n",
    "Load the dataset containing emotional scores and align it with the medical dataset based on a common identifier (e.g., patient ID).\n",
    "\n",
    "**Reasoning**:\n",
    "Load the emotional scores dataset and display its head and info to understand its structure.\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "print(\"Please upload the 'emotional_scores.csv' file.\")\n",
    "uploaded_emotion = files.upload()\n",
    "\n",
    "for file_name in uploaded_emotion.keys():\n",
    "    df_emotion = pd.read_csv(io.BytesIO(uploaded_emotion[file_name]))\n",
    "\n",
    "print(\"\\nEmotional Scores Dataset Head:\")\n",
    "display(df_emotion.head())\n",
    "\n",
    "print(\"\\nEmotional Scores Dataset Info:\")\n",
    "df_emotion.info()\n",
    "\n",
    "\"\"\"## Combine datasets\n",
    "\n",
    "### Subtask:\n",
    "Merge the preprocessed medical data (assuming it's available from previous steps) and emotional scores into a single DataFrame.\n",
    "\n",
    "**Reasoning**:\n",
    "The previous attempt to load a separate emotional scores file failed because the user uploaded the same medical dataset. However, the subtask explicitly asks to merge the \"preprocessed medical data (assuming it's available from previous steps)\" with \"emotional scores from 'emotional_scores.csv'\". The kernel state shows `df_emotion` is available and contains the medical data, which is likely the \"emotional scores\" data the user intended to use, albeit being the same format as the original medical data. I will proceed by merging the `df` (original medical data) and `df_emotion` (the second uploaded data, assumed to contain the intended emotional scores, despite its column names) based on `patient_id` as requested in the instructions. I will perform a left merge, keeping all records from `df`, then display the head and info of the merged dataframe.\n",
    "\n",
    "**Reasoning**:\n",
    "The previous command failed because the `df` DataFrame was not defined in the current execution environment. This happened because the data loading step for `df` was in a code cell that was not executed in the current runtime. To fix this, I need to load the data into `df` first, then proceed with the merge.\n",
    "\"\"\"\n",
    "\n",
    "# Load the medical data into df\n",
    "print(\"Please upload your medical record dataset (e.g., synthetic emr dataset.csv) for df.\")\n",
    "uploaded_df = files.upload()\n",
    "\n",
    "for file_name in uploaded_df.keys():\n",
    "    df = pd.read_csv(io.BytesIO(uploaded_df[file_name]))\n",
    "\n",
    "# Assuming 'df' contains the original medical data and 'df_emotion' contains the \"emotional scores\" data from the second upload.\n",
    "# Merge the two DataFrames based on 'patient_id'\n",
    "# Use suffixes to differentiate columns that exist in both dataframes other than 'patient_id'\n",
    "df_combined = pd.merge(df, df_emotion, on='patient_id', how='left', suffixes=('_medical', '_emotion'))\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(\"Combined DataFrame Head:\")\n",
    "display(df_combined.head())\n",
    "\n",
    "# Display information about the merged DataFrame\n",
    "print(\"\\nCombined DataFrame Info:\")\n",
    "df_combined.info()\n",
    "\n",
    "\"\"\"## Feature engineering\n",
    "\n",
    "### Subtask:\n",
    "Combine the TF-IDF features from the medical text data with the emotional scores and any other relevant numerical features from the combined dataset.\n",
    "\n",
    "**Reasoning**:\n",
    "Select the relevant numerical and emotional score columns from the combined dataframe, convert them to a numpy array, convert the sparse TF-IDF matrix to a dense numpy array, concatenate the dense arrays, and verify the shape of the combined array.\n",
    "\n",
    "**Reasoning**:\n",
    "The previous code failed because the variable `X` (containing the TF-IDF features) was not defined in the current execution environment. The data loading and TF-IDF vectorization steps need to be included in this code block to ensure `X` and `y` (for splitting) are available before attempting to combine features. The subtask is to combine features, which requires `X` to exist.\n",
    "\"\"\"\n",
    "\n",
    "# Load the medical data into df\n",
    "print(\"Please upload your medical record dataset (e.g., synthetic emr dataset.csv) for df.\")\n",
    "uploaded_df = files.upload()\n",
    "\n",
    "for file_name in uploaded_df.keys():\n",
    "    df = pd.read_csv(io.BytesIO(uploaded_df[file_name]))\n",
    "\n",
    "# Assuming 'df_emotion' is loaded from a previous step and contains the \"emotional scores\" data.\n",
    "# If df_emotion was not successfully loaded or was the wrong file, this merge will still proceed\n",
    "# but the emotional columns will be NaN or duplicate medical columns as observed previously.\n",
    "# We will proceed assuming df_emotion exists from the previous execution trace.\n",
    "df_combined = pd.merge(df, df_emotion, on='patient_id', how='left', suffixes=('_medical', '_emotion'))\n",
    "\n",
    "\n",
    "# Clean and preprocess the symptoms data for TF-IDF\n",
    "df_combined['symptoms_medical'] = df_combined['symptoms_medical'].fillna('no symptoms')\n",
    "df_combined['symptoms_medical'] = df_combined['symptoms_medical'].apply(lambda x: ' '.join(str(x).split(',')))\n",
    "\n",
    "# Vectorize the symptoms column using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "X = tfidf_vectorizer.fit_transform(df_combined['symptoms_medical'])\n",
    "\n",
    "# Encode the target variable (medical conditions)\n",
    "le_condition = LabelEncoder()\n",
    "# Use the medical condition from the medical side of the merged dataframe\n",
    "y = le_condition.fit_transform(df_combined['medical_condition_medical'].fillna(\"Unknown\"))\n",
    "\n",
    "\n",
    "# Step 1: Select relevant numerical and emotional score columns\n",
    "# Based on the df_combined structure, we'll select 'age_medical'.\n",
    "# If actual emotional score columns existed (e.g., 'anger_score_emotion'),\n",
    "# we would add them here.\n",
    "relevant_features_df = df_combined[['age_medical']] # Select the age column from the merged df\n",
    "\n",
    "# Step 2: Convert the selected numerical and emotional features DataFrame into a NumPy array.\n",
    "numerical_emotional_features = relevant_features_df.values\n",
    "\n",
    "# Step 3: Convert the sparse TF-IDF array to a dense NumPy array.\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Step 4: Concatenate the dense TF-IDF array and the array of numerical/emotional features horizontally.\n",
    "X_combined = np.hstack((X_dense, numerical_emotional_features))\n",
    "\n",
    "# Step 5: Verify the shape of the combined feature array.\n",
    "print(\"Shape of TF-IDF features (sparse):\", X.shape)\n",
    "print(\"Shape of TF-IDF features (dense):\", X_dense.shape)\n",
    "print(\"Shape of numerical/emotional features:\", numerical_emotional_features.shape)\n",
    "print(\"Shape of combined features:\", X_combined.shape)\n",
    "\n",
    "\"\"\"## Model training\n",
    "\n",
    "### Subtask:\n",
    "Train a classification model (e.g., Random Forest, Gradient Boosting, or an ensemble) on the combined feature set to predict medical conditions.\n",
    "\n",
    "**Reasoning**:\n",
    "Split the combined features and target variable into training and testing sets and train a Random Forest classifier on the training data.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Split the combined feature set and the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Choose and instantiate a classification model (Random Forest)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Step 3: Train the model on the training data\n",
    "print(\"Starting Random Forest Model training on combined features...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "The model has been trained. Now, evaluate the model's performance on the test set using appropriate metrics, including accuracy, classification report, and confusion matrix, as outlined in the overall task.\n",
    "\n",
    "**Reasoning**:\n",
    "The previous code block failed because `precision_recall_fscore_support` was not imported. Import the necessary function and re-run the evaluation steps.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nRandom Forest Model Accuracy (Combined Features): {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Combined Features):\")\n",
    "# Ensure le_condition is available from previous steps for target_names\n",
    "print(classification_report(y_test, y_pred, target_names=le_condition.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "# Ensure le_condition is available from previous steps for xticklabels and yticklabels\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Random Forest - Combined Features)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score for Macro and Weighted averages\n",
    "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")\n",
    "weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "# Display Macro and Weighted Average Metrics\n",
    "print(\"\\nMacro Average Metrics (Combined Features):\")\n",
    "print(f\"Precision: {macro_precision:.2f}, Recall: {macro_recall:.2f}, F1 Score: {macro_f1:.2f}\")\n",
    "\n",
    "print(\"\\nWeighted Average Metrics (Combined Features):\")\n",
    "print(f\"Precision: {weighted_precision:.2f}, Recall: {weighted_recall:.2f}, F1 Score: {weighted_f1:.2f}\")\n",
    "\n",
    "\"\"\"## Model evaluation\n",
    "\n",
    "### Subtask:\n",
    "Evaluate the performance of the model trained on the combined data using appropriate metrics (accuracy, classification report, confusion matrix).\n",
    "\n",
    "## Summary:\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "*   The initial attempt to load \"emotional\\_scores.csv\" resulted in the same medical dataset being loaded, not a separate emotional scores dataset.\n",
    "*   After successfully loading both the medical dataset and (what was believed to be) the emotional scores dataset, a left merge was performed on `patient_id`, creating `df_combined`. Due to the content of the \"emotional scores\" file, this merge resulted in duplicated columns with `_medical` and `_emotion` suffixes.\n",
    "*   TF-IDF features were successfully extracted from the 'symptoms\\_medical' column of the combined dataframe.\n",
    "*   The 'age\\_medical' column was selected as a numerical feature and successfully combined with the dense TF-IDF features, resulting in a feature matrix `X_combined` with a shape reflecting the inclusion of age.\n",
    "*   A Random Forest classifier was trained on the `X_combined` features to predict medical conditions.\n",
    "*   The trained model achieved an accuracy of 60.71% on the test set.\n",
    "*   The classification report and confusion matrix revealed varying performance across different medical conditions, with some classes predicted more accurately than others.\n",
    "\n",
    "### Insights or Next Steps\n",
    "\n",
    "*   Investigate the content of the \"emotional\\_scores.csv\" file to ensure it contains actual emotional scores. If not, obtain or generate appropriate emotional data for a more meaningful analysis of its impact on medical condition prediction.\n",
    "*   Explore alternative classification models or hyperparameter tuning for the Random Forest model to potentially improve the prediction accuracy, especially for classes with lower recall or precision.\n",
    "\n",
    "## Load and preprocess emotional scores\n",
    "\n",
    "### Subtask:\n",
    "Load the dataset containing emotional scores and align it with the medical dataset based on a common identifier (e.g., patient ID).\n",
    "\n",
    "**Reasoning**:\n",
    "Load the emotional scores dataset and display its head and info to understand its structure.\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "print(\"Please upload the 'emotional_scores.csv' file.\")\n",
    "uploaded_emotion = files.upload()\n",
    "\n",
    "for file_name in uploaded_emotion.keys():\n",
    "    df_emotion = pd.read_csv(io.BytesIO(uploaded_emotion[file_name]))\n",
    "\n",
    "print(\"\\nEmotional Scores Dataset Head:\")\n",
    "display(df_emotion.head())\n",
    "\n",
    "print(\"\\nEmotional Scores Dataset Info:\")\n",
    "df_emotion.info()\n",
    "\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "print(\"Please upload the 'EMR_with_emotions.csv' file.\")\n",
    "uploaded_emotion = files.upload()\n",
    "\n",
    "for file_name in uploaded_emotion.keys():\n",
    "    df_emotion = pd.read_csv(io.BytesIO(uploaded_emotion[file_name]))\n",
    "\n",
    "print(\"\\nEmotional Scores Dataset Head:\")\n",
    "display(df_emotion.head())\n",
    "\n",
    "print(\"\\nEmotional Scores Dataset Info:\")\n",
    "df_emotion.info()\n",
    "\n",
    "\"\"\"## Combine datasets\n",
    "\n",
    "### Subtask:\n",
    "Merge the preprocessed medical data (assuming it's available from previous steps) and emotional scores into a single DataFrame.\n",
    "\n",
    "**Reasoning**:\n",
    "Merge the preprocessed medical data (assuming it's available in `df`) and the loaded emotional scores (`df_emotion`) into a single DataFrame using 'patient_id' as the key. Display the head and info of the merged DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "# Assuming 'df' contains the original medical data and 'df_emotion' contains the \"emotional scores\" data from the second upload.\n",
    "# Merge the two DataFrames based on 'patient_id'\n",
    "# Use suffixes to differentiate columns that exist in both dataframes other than 'patient_id'\n",
    "df_combined = pd.merge(df, df_emotion, on='patient_id', how='left', suffixes=('_medical', '_emotion'))\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(\"Combined DataFrame Head:\")\n",
    "display(df_combined.head())\n",
    "\n",
    "# Display information about the merged DataFrame\n",
    "print(\"\\nCombined DataFrame Info:\")\n",
    "df_combined.info()\n",
    "\n",
    "\"\"\"## Feature engineering\n",
    "\n",
    "### Subtask:\n",
    "Combine the TF-IDF features from the medical text data with the emotional scores and any other relevant numerical features from the combined dataset.\n",
    "\n",
    "**Reasoning**:\n",
    "Select the relevant numerical and emotional score columns from the combined dataframe, convert them to a numpy array, convert the sparse TF-IDF matrix to a dense numpy array, concatenate the dense arrays, and verify the shape of the combined array.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np # Import numpy if not already imported in this cell context\n",
    "\n",
    "# Step 1: Select relevant numerical and emotional score columns\n",
    "# Based on the df_combined structure from the previous step,\n",
    "# the 'emotional_scores.csv' file appears to have been a duplicate of the\n",
    "# medical dataset, resulting in duplicated columns. We will use 'age_medical'\n",
    "# as the representative numerical feature from the \"emotional\" side,\n",
    "# as there are no distinct emotional score columns.\n",
    "relevant_features_df = df_combined[['age_medical']] # Select the age column from the merged df\n",
    "\n",
    "# Step 2: Convert the selected numerical and emotional features DataFrame into a NumPy array.\n",
    "numerical_emotional_features = relevant_features_df.values\n",
    "\n",
    "# Ensure TF-IDF features (X) are available from previous steps.\n",
    "# Assuming the TF-IDF vectorization was performed on df_combined['symptoms_medical']\n",
    "# in a previous executed cell and stored in a variable named 'X'.\n",
    "# If 'X' is not defined, the previous TF-IDF step needs to be re-run first.\n",
    "\n",
    "# Step 3: Convert the sparse TF-IDF array to a dense NumPy array.\n",
    "# Assuming 'X' is a sparse matrix from TfidfVectorizer\n",
    "try:\n",
    "    X_dense = X.toarray()\n",
    "except NameError:\n",
    "    print(\"Error: TF-IDF features (X) are not defined. Please run the TF-IDF vectorization step first.\")\n",
    "    # You would typically stop execution or re-run the TF-IDF step here.\n",
    "    # For this example, we'll assume X is available from a previous execution.\n",
    "    # If you are running this block independently, you need to include the\n",
    "    # TF-IDF vectorization code before this step.\n",
    "    raise # Re-raise the error if X is not defined\n",
    "\n",
    "\n",
    "# Step 4: Concatenate the dense TF-IDF array and the array of numerical/emotional features horizontally.\n",
    "X_combined = np.hstack((X_dense, numerical_emotional_features))\n",
    "\n",
    "# Step 5: Verify the shape of the combined feature array.\n",
    "print(\"Shape of TF-IDF features (sparse):\", X.shape)\n",
    "print(\"Shape of TF-IDF features (dense):\", X_dense.shape)\n",
    "print(\"Shape of numerical/emotional features:\", numerical_emotional_features.shape)\n",
    "print(\"Shape of combined features:\", X_combined.shape)\n",
    "\n",
    "\"\"\"## Model training\n",
    "\n",
    "### Subtask:\n",
    "Train a classification model (e.g., Random Forest, Gradient Boosting, or an ensemble) on the combined feature set to predict medical conditions.\n",
    "\n",
    "**Reasoning**:\n",
    "Split the combined features and target variable into training and testing sets and train a Random Forest classifier on the training data.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Step 1: Split the combined feature set and the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Choose and instantiate a classification model (Random Forest)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Step 3: Train the model on the training data\n",
    "print(\"Starting Random Forest Model training on combined features...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "\"\"\"## Model evaluation\n",
    "\n",
    "### Subtask:\n",
    "Evaluate the performance of the model trained on the combined data using appropriate metrics (accuracy, classification report, confusion matrix).\n",
    "\n",
    "**Reasoning**:\n",
    "The model has been trained. Now, evaluate the model's performance on the test set using appropriate metrics, including accuracy, classification report, and confusion matrix, as outlined in the overall task.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nRandom Forest Model Accuracy (Combined Features): {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Combined Features):\")\n",
    "# Ensure le_condition is available from previous steps for target_names\n",
    "print(classification_report(y_test, y_pred, target_names=le_condition.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "# Ensure le_condition is available from previous steps for xticklabels and yticklabels\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Random Forest - Combined Features)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score for Macro and Weighted averages\n",
    "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")\n",
    "weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "# Display Macro and Weighted Average Metrics\n",
    "print(\"\\nMacro Average Metrics (Combined Features):\")\n",
    "print(f\"Precision: {macro_precision:.2f}, Recall: {macro_recall:.2f}, F1 Score: {macro_f1:.2f}\")\n",
    "\n",
    "print(\"\\nWeighted Average Metrics (Combined Features):\")\n",
    "print(f\"Precision: {weighted_precision:.2f}, Recall: {weighted_recall:.2f}, F1 Score: {weighted_f1:.2f}\")\n",
    "\n",
    "\"\"\"## Summary:\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "* The initial attempt to load \"emotional\\_scores.csv\" resulted in the same medical dataset being loaded, not a separate emotional scores dataset.\n",
    "* After successfully loading both the medical dataset and (what was believed to be) the emotional scores dataset, a left merge was performed on `patient_id`, creating `df_combined`. Due to the content of the \"emotional scores\" file, this merge resulted in duplicated columns with `_medical` and `_emotion` suffixes.\n",
    "* TF-IDF features were successfully extracted from the 'symptoms\\_medical' column of the combined dataframe.\n",
    "* The 'age\\_medical' column was selected as a numerical feature and successfully combined with the dense TF-IDF features, resulting in a feature matrix `X_combined` with a shape reflecting the inclusion of age.\n",
    "* A Random Forest classifier was trained on the `X_combined` features to predict medical conditions.\n",
    "* The trained model achieved an accuracy of 89.50% on the test set.\n",
    "* The classification report and confusion matrix revealed varying performance across different medical conditions, with some classes predicted more accurately than others.\n",
    "\n",
    "### Insights or Next Steps\n",
    "\n",
    "* Investigate the content of the \"emotional\\_scores.csv\" file to ensure it contains actual emotional scores. If not, obtain or generate appropriate emotional data for a more meaningful analysis of its impact on medical condition prediction.\n",
    "* Compare the performance of this model (trained with TF-IDF + age) to the performance of models trained solely on TF-IDF features (as seen in earlier cells) to assess the impact of including the 'age' feature.\n",
    "* Explore alternative classification models or hyperparameter tuning for the Random Forest model to potentially improve the prediction accuracy, especially for classes with lower recall or precision.\n",
    "* If actual emotional scores data is obtained, repeat the process of combining features and training/evaluating a model to determine if emotional scores contribute to better medical condition prediction.\n",
    "* Consider more advanced text preprocessing or feature engineering techniques for the clinical notes and symptoms.\n",
    "\n",
    "# Task\n",
    "Combine the dataset with emotional scores to retrieve the type of medical condition or disease using clinical notes and symptoms, incorporating a neuro-symbolic NLP technique.\n",
    "\n",
    "## Identify and represent symbolic knowledge\n",
    "\n",
    "### Subtask:\n",
    "Define and represent the relevant medical knowledge (e.g., symptom-disease relationships, medical concepts) in a structured format suitable for integration. This could involve creating a knowledge graph, a rule base, or a simple dictionary.\n",
    "\n",
    "**Reasoning**:\n",
    "Create a dictionary to represent a simplified medical knowledge base mapping symptoms to potential medical conditions and print it.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Create a Python dictionary to represent a simplified medical knowledge base\n",
    "# Step 2: Populate this knowledge base with a few relevant symptom-disease relationships\n",
    "medical_knowledge_base = {\n",
    "    'fever': ['Infection', 'Influenza', 'Malaria', 'Typhoid'],\n",
    "    'cough': ['COPD', 'Asthma', 'Infection'],\n",
    "    'wheezing': ['COPD', 'Asthma'],\n",
    "    'shortness of breath': ['COPD', 'Asthma', 'Heart Disease'],\n",
    "    'chest pain': ['Heart Disease'],\n",
    "    'headache': ['Hypertension', 'Malaria', 'Typhoid'],\n",
    "    'nausea': ['Ulcer', 'Typhoid'],\n",
    "    'vomiting': ['Ulcer', 'Typhoid'],\n",
    "    'bloating': ['Ulcer'],\n",
    "    'swollen lymph nodes': ['HIV'],\n",
    "    'weight loss': ['HIV', 'Diabetes'],\n",
    "    'frequent urination': ['Diabetes'],\n",
    "    'increased thirst': ['Diabetes'],\n",
    "    'muscle pain': ['Malaria', 'Typhoid'],\n",
    "    'chills': ['Malaria', 'Typhoid', 'Infection'],\n",
    "    'fatigue': ['HIV', 'Diabetes', 'COPD', 'Asthma', 'Heart Disease', 'Unknown'],\n",
    "    'no symptoms': ['Unknown']\n",
    "}\n",
    "\n",
    "# Step 3: Print the created knowledge base\n",
    "print(\"Simplified Medical Knowledge Base:\")\n",
    "for symptom, conditions in medical_knowledge_base.items():\n",
    "    print(f\"- {symptom}: {conditions}\")\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "The symbolic knowledge base has been defined. Now, integrate this knowledge base into the feature engineering process by creating new features based on the symptom-disease relationships for each patient's symptoms and combine them with the existing features.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Assuming 'df_combined' is available from previous steps and contains the merged data\n",
    "# Assuming 'medical_knowledge_base' is available from the previous step\n",
    "\n",
    "# Ensure df_combined is properly preprocessed for symptoms\n",
    "df_combined['symptoms_medical'] = df_combined['symptoms_medical'].fillna('no symptoms')\n",
    "df_combined['symptoms_medical'] = df_combined['symptoms_medical'].apply(lambda x: ' '.join(str(x).split(',')))\n",
    "\n",
    "# Re-vectorize the symptoms column using TF-IDF on the updated df_combined\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "X = tfidf_vectorizer.fit_transform(df_combined['symptoms_medical'])\n",
    "\n",
    "# Re-encode the target variable (medical conditions)\n",
    "le_condition = LabelEncoder()\n",
    "y = le_condition.fit_transform(df_combined['medical_condition_medical'].fillna(\"Unknown\"))\n",
    "\n",
    "# Get the list of all unique medical conditions from the target variable\n",
    "all_conditions = list(le_condition.classes_)\n",
    "\n",
    "\n",
    "# Function to Generate Symbolic Features based on the defined knowledge base\n",
    "def generate_symbolic_features(symptoms_text, knowledge_base, all_possible_conditions):\n",
    "    \"\"\"\n",
    "    Generates symbolic features based on the presence of symptoms related to each condition\n",
    "    in the knowledge base.\n",
    "\n",
    "    Args:\n",
    "        symptoms_text (str): The cleaned symptoms text for a single patient.\n",
    "        knowledge_base (dict): The medical knowledge base mapping symptoms to conditions.\n",
    "        all_possible_conditions (list): A list of all possible medical conditions.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of symbolic features, where each element\n",
    "                       represents a count or binary indicator related to a specific condition.\n",
    "    \"\"\"\n",
    "    # Initialize feature vector with zeros for all conditions\n",
    "    # We'll use counts of relevant symptoms for each condition\n",
    "    symbolic_feature_counts = {condition: 0 for condition in all_possible_conditions}\n",
    "\n",
    "    # Split the symptoms text into individual symptom terms\n",
    "    individual_symptom_terms = symptoms_text.split()\n",
    "\n",
    "    # Iterate through the individual symptom terms for the patient\n",
    "    for term in individual_symptom_terms:\n",
    "        # Iterate through the symptoms in the knowledge base\n",
    "        for kb_symptom, associated_conditions in knowledge_base.items():\n",
    "            # Simple check if the symptom term matches a key in the knowledge base\n",
    "            # More sophisticated matching (fuzzy, stemming, concept linking) could be used here\n",
    "            if term == kb_symptom:\n",
    "                # If a match is found, increment the count for the associated conditions\n",
    "                for condition in associated_conditions:\n",
    "                     # Ensure the condition is one of our target conditions\n",
    "                    if condition in symbolic_feature_counts:\n",
    "                        symbolic_feature_counts[condition] += 1\n",
    "\n",
    "    # Convert the dictionary of counts to a list/array in the same order as all_possible_conditions\n",
    "    feature_vector = [symbolic_feature_counts[condition] for condition in all_possible_conditions]\n",
    "\n",
    "    return np.array(feature_vector)\n",
    "\n",
    "\n",
    "# Apply the function to your DataFrame to generate symbolic features\n",
    "# This will create a Series where each element is a NumPy array (the feature vector for a row)\n",
    "symbolic_features_series = df_combined['symptoms_medical'].apply(\n",
    "    lambda x: generate_symbolic_features(x, medical_knowledge_base, all_conditions)\n",
    ")\n",
    "\n",
    "# Convert the Series of arrays into a 2D NumPy array\n",
    "symbolic_features_array = np.vstack(symbolic_features_series.values)\n",
    "\n",
    "# Select the numerical features (e.g., age)\n",
    "# Based on previous steps, 'age_medical' is available in df_combined\n",
    "numerical_features = df_combined[['age_medical']].values\n",
    "\n",
    "\n",
    "# Combine the TF-IDF features, symbolic features, and numerical features\n",
    "# Convert sparse TF-IDF to dense before stacking\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Concatenate the dense TF-IDF array, symbolic features array, and numerical features array\n",
    "X_combined_neuro_symbolic = np.hstack((X_dense, symbolic_features_array, numerical_features))\n",
    "\n",
    "\n",
    "# Verify the shape of the combined feature array\n",
    "print(\"Shape of TF-IDF features (dense):\", X_dense.shape)\n",
    "print(\"Shape of Symbolic features:\", symbolic_features_array.shape)\n",
    "print(\"Shape of Numerical features:\", numerical_features.shape)\n",
    "print(\"Shape of combined (Neuro-Symbolic) features:\", X_combined_neuro_symbolic.shape)\n",
    "\n",
    "# Split the combined data for training and testing\n",
    "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(\n",
    "    X_combined_neuro_symbolic, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nData splitting complete for neuro-symbolic approach.\")\n",
    "print(\"Shape of X_train_ns:\", X_train_ns.shape)\n",
    "print(\"Shape of X_test_ns:\", X_test_ns.shape)\n",
    "print(\"Shape of y_train_ns:\", y_train_ns.shape)\n",
    "print(\"Shape of y_test_ns:\", y_test_ns.shape)\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "Train a classification model on the combined neuro-symbolic features and evaluate its performance.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Choose and instantiate a classification model (Random Forest)\n",
    "# Using the same model as trained on just TF-IDF + Age for comparison\n",
    "rf_model_ns = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Train the model on the combined neuro-symbolic training data\n",
    "print(\"Starting Random Forest Model training on combined neuro-symbolic features...\")\n",
    "rf_model_ns.fit(X_train_ns, y_train_ns)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Step 3: Evaluate the Model on the test set\n",
    "y_pred_ns = rf_model_ns.predict(X_test_ns)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_ns = accuracy_score(y_test_ns, y_pred_ns)\n",
    "print(f\"\\nRandom Forest Model Accuracy (Neuro-Symbolic Features): {accuracy_ns * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Neuro-Symbolic Features):\")\n",
    "# Ensure le_condition is available from previous steps for target_names\n",
    "print(classification_report(y_test_ns, y_pred_ns, target_names=le_condition.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_ns = confusion_matrix(y_test_ns, y_pred_ns)\n",
    "plt.figure(figsize=(10, 7))\n",
    "# Ensure le_condition is available from previous steps for xticklabels and yticklabels\n",
    "sns.heatmap(conf_matrix_ns, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Random Forest - Neuro-Symbolic Features)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score for Macro and Weighted averages\n",
    "macro_precision_ns, macro_recall_ns, macro_f1_ns, _ = precision_recall_fscore_support(y_test_ns, y_pred_ns, average=\"macro\")\n",
    "weighted_precision_ns, weighted_recall_ns, weighted_f1_ns, _ = precision_recall_fscore_support(y_test_ns, y_pred_ns, average=\"weighted\")\n",
    "\n",
    "# Display Macro and Weighted Average Metrics\n",
    "print(\"\\nMacro Average Metrics (Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {macro_precision_ns:.2f}, Recall: {macro_recall_ns:.2f}, F1 Score: {macro_f1_ns:.2f}\")\n",
    "\n",
    "print(\"\\nWeighted Average Metrics (Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {weighted_precision_ns:.2f}, Recall: {weighted_recall_ns:.2f}, F1 Score: {weighted_f1_ns:.2f}\")\n",
    "\n",
    "\"\"\"## Analyze and interpret results\n",
    "\n",
    "### Subtask:\n",
    "Analyze the performance of the neuro-symbolic model and interpret how the symbolic knowledge influenced the predictions.\n",
    "\n",
    "**Reasoning**:\n",
    "Compare the performance metrics of the neuro-symbolic model with previous models, analyze the confusion matrices and classification reports, and discuss the impact of symbolic knowledge on predictions based on the knowledge base.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Compare overall accuracy\n",
    "print(\"--- Performance Comparison ---\")\n",
    "print(f\"Accuracy (Neuro-Symbolic Features): {accuracy_ns * 100:.2f}%\")\n",
    "\n",
    "# Assume 'accuracy' from cell 422f61fa is the model trained on TF-IDF + Age\n",
    "try:\n",
    "    print(f\"Accuracy (TF-IDF + Age Features): {accuracy * 100:.2f}%\")\n",
    "except NameError:\n",
    "    print(\"Accuracy for TF-IDF + Age features not available from previous runs.\")\n",
    "\n",
    "# Assume 'accuracy' from cell QMUEVD39SK3c is the Random Forest model trained on TF-IDF only\n",
    "# Note: This is a different Random Forest model instance, but provides a baseline\n",
    "try:\n",
    "    # Need to re-run the RF TF-IDF only cell to get its accuracy variable name\n",
    "    # As the variable name might be overwritten in later cells\n",
    "    # For now, we'll just print a placeholder or try to access the variable if we know its name\n",
    "    # Based on the output of QMUEVD39SK3c, the variable was also named 'accuracy'\n",
    "    # This is ambiguous, so we'll refer to the printed output\n",
    "    print(\"\\nRefer to previous cell outputs for Accuracy (TF-IDF only Random Forest): 89.00%\") # Hardcoded based on previous output\n",
    "except NameError:\n",
    "    print(\"Accuracy for TF-IDF only Random Forest not directly accessible.\")\n",
    "\n",
    "\n",
    "# Step 2 & 3: Analyze Confusion Matrices and Classification Reports\n",
    "print(\"\\n--- Analysis of Confusion Matrices and Classification Reports ---\")\n",
    "print(\"Comparing Classification Report (Neuro-Symbolic) vs (TF-IDF + Age):\")\n",
    "\n",
    "# Re-print classification report for TF-IDF + Age for easy comparison\n",
    "# Assuming the output from cell 422f61fa is available above this cell's output\n",
    "print(\"\\nClassification Report (TF-IDF + Age Features):\")\n",
    "# Need to re-calculate or re-print the report from the previous run if not already visible\n",
    "# Assuming the report from cell 422f61fa is visible in the output above.\n",
    "# If not, you would need to re-calculate it here using y_test and y_pred from that model.\n",
    "\n",
    "print(\"\\nClassification Report (Neuro-Symbolic Features):\")\n",
    "print(classification_report(y_test_ns, y_pred_ns, target_names=le_condition.classes_))\n",
    "\n",
    "\n",
    "print(\"\\nObserving changes in Confusion Matrices:\")\n",
    "print(\"Compare the Confusion Matrix (Random Forest - Neuro-Symbolic Features) shown above\")\n",
    "print(\"with the Confusion Matrix (Random Forest - Combined Features) from the previous run.\")\n",
    "print(\"Look for changes in diagonal values (True Positives) and off-diagonal values (False Positives/Negatives) for each class.\")\n",
    "\n",
    "# Step 4: Discuss the impact of symbolic knowledge\n",
    "print(\"\\n--- Impact of Symbolic Knowledge ---\")\n",
    "print(\"The symbolic features added to the model are counts of symptoms related to each medical condition based on the 'medical_knowledge_base'.\")\n",
    "print(\"These features provide the model with explicit, structured information about symptom-disease associations.\")\n",
    "print(\"Let's consider some examples based on the knowledge base and potential performance changes:\")\n",
    "\n",
    "print(\"\\nExample 1: Ulcer\")\n",
    "print(f\"Symptoms in KB for Ulcer: {medical_knowledge_base.get('bloating', []) + medical_knowledge_base.get('nausea', []) + medical_knowledge_base.get('vomiting', [])}\")\n",
    "print(\"If a patient's notes contain 'bloating', 'nausea', and 'vomiting', the symbolic feature for 'Ulcer' will have a high count.\")\n",
    "print(\"This strong, specific association in the KB likely helps the model correctly identify Ulcer cases, potentially leading to high precision and recall for this class.\")\n",
    "# Look at the confusion matrices - check if Ulcer had high true positives and low false positives/negatives in both models, and if NS is better.\n",
    "\n",
    "print(\"\\nExample 2: HIV\")\n",
    "print(f\"Symptoms in KB for HIV: {medical_knowledge_base.get('swollen lymph nodes', []) + medical_knowledge_base.get('weight loss', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(\"Swollen lymph nodes and weight loss are relatively specific symptoms for HIV in this simplified KB.\")\n",
    "print(\"The symbolic features for HIV would increase when these symptoms are present, potentially improving the model's ability to distinguish HIV from other conditions.\")\n",
    "# Check HIV's metrics and confusion matrix entries.\n",
    "\n",
    "print(\"\\nExample 3: Conditions with overlapping symptoms (e.g., COPD, Asthma, Infection)\")\n",
    "print(f\"Symptoms in KB for COPD: {medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('wheezing', []) + medical_knowledge_base.get('shortness of breath', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(f\"Symptoms in KB for Asthma: {medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('wheezing', []) + medical_knowledge_base.get('shortness of breath', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(f\"Symptoms in KB for Infection: {medical_knowledge_base.get('fever', []) + medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('chills', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(\"Since these conditions share symptoms like cough and fatigue in the KB, the symbolic features might not provide as much discriminative power as for conditions with more unique symptom profiles in the KB.\")\n",
    "print(\"Performance improvements for these classes might be less pronounced, or the model might still struggle to differentiate between them.\")\n",
    "# Examine confusion matrix entries between these classes (e.g., predicted COPD vs True Asthma).\n",
    "\n",
    "print(\"\\nOverall, the symbolic features likely act as a form of 'prior knowledge' or 'attention mechanism', guiding the model to pay more attention to symptoms that are medically relevant to specific conditions according to the knowledge base.\")\n",
    "print(\"This helps the model leverage established medical associations beyond just learning patterns from symptom term co-occurrences in the text data alone.\")\n",
    "print(\"Conditions with clear and relatively unique symptom definitions in the knowledge base are likely to see the most significant benefit from the inclusion of these symbolic features.\")\n",
    "\n",
    "# Step 5: Summarize the analysis (will be done in a markdown cell after this code block executes)\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "Summarize the analysis of the neuro-symbolic model's performance and the impact of symbolic knowledge as requested in the final step of the subtask.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Step 5: Summarize the analysis in a markdown cell.\n",
    "# This will be a markdown cell following this code block.\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "Summarize the analysis of the neuro-symbolic model's performance and the impact of symbolic knowledge based on the output of the previous code block, fulfilling the final instruction of the subtask.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is a placeholder cell to satisfy the response format requirements.\n",
    "# The actual summary will be in the following markdown cell.\n",
    "print(\"Proceeding to summary.\")\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "Provide a summary of the analysis of the neuro-symbolic model's performance and the impact of the incorporated symbolic knowledge, as requested in the final instruction of the subtask.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# No code is needed for the summary, it will be a markdown cell.\n",
    "\n",
    "\"\"\"## Refine symbolic knowledge and model\n",
    "\n",
    "### Subtask:\n",
    "Based on the analysis, refine the symbolic knowledge representation and/or the model architecture for improved performance and interpretability.\n",
    "\n",
    "**Reasoning**:\n",
    "Review the classification report and confusion matrix from the neuro-symbolic model's evaluation to identify areas for improvement, then refine the symbolic knowledge representation and retrain the model based on those insights. Finally, re-evaluate the refined model and compare its performance.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Review the classification report and confusion matrix from the neuro-symbolic model's evaluation.\n",
    "# The classification report and confusion matrix were printed in the previous execution of cell 3c2e6158.\n",
    "# Observing the output, some classes like 'Asthma' and 'Heart Disease' still have lower recall and F1-scores\n",
    "# compared to others, suggesting potential areas for improvement.\n",
    "\n",
    "print(\"Reviewing previous Classification Report (Neuro-Symbolic Features):\")\n",
    "# The report is available in the previous cell's output. Let's print it again for clarity.\n",
    "print(classification_report(y_test_ns, y_pred_ns, target_names=le_condition.classes_))\n",
    "\n",
    "print(\"\\nReviewing previous Confusion Matrix (Neuro-Symbolic Features):\")\n",
    "# The confusion matrix plot is available in the previous cell's output. We can visually inspect it.\n",
    "# For analysis purposes, we can print the matrix values if needed:\n",
    "# print(conf_matrix_ns)\n",
    "\n",
    "# Based on the report, 'Asthma' (recall 0.56) and 'Heart Disease' (recall 0.59) are candidates for refinement.\n",
    "\n",
    "# Step 2 & 3: Examine the medical_knowledge_base and consider refinement.\n",
    "# Current KB entries for these conditions:\n",
    "# 'Asthma': ['cough', 'wheezing', 'shortness of breath', 'fatigue']\n",
    "# 'Heart Disease': ['shortness of breath', 'chest pain', 'fatigue']\n",
    "\n",
    "# Refinement Idea: Add more specific or common symptoms for Asthma and Heart Disease\n",
    "# (This is a simplified example; real refinement needs medical expertise and data analysis)\n",
    "refined_medical_knowledge_base = medical_knowledge_base.copy()\n",
    "# Add 'tightness in chest' and 'difficulty breathing' for Asthma\n",
    "refined_medical_knowledge_base['tightness in chest'] = ['Asthma']\n",
    "refined_medical_knowledge_base['difficulty breathing'] = ['Asthma', 'COPD', 'Heart Disease'] # Overlap with other conditions\n",
    "# Add 'palpitations' and 'dizziness' for Heart Disease\n",
    "refined_medical_knowledge_base['palpitations'] = ['Heart Disease']\n",
    "refined_medical_knowledge_base['dizziness'] = ['Heart Disease', 'Hypertension', 'Unknown'] # Overlap\n",
    "\n",
    "print(\"\\nRefined Medical Knowledge Base (Partial View):\")\n",
    "print(f\"- tightness in chest: {refined_medical_knowledge_base.get('tightness in chest')}\")\n",
    "print(f\"- difficulty breathing: {refined_medical_knowledge_base.get('difficulty breathing')}\")\n",
    "print(f\"- palpitations: {refined_medical_knowledge_base.get('palpitations')}\")\n",
    "print(f\"- dizziness: {refined_medical_knowledge_base.get('dizziness')}\")\n",
    "\n",
    "\n",
    "# Step 4: Implement the chosen refinements.\n",
    "# We will regenerate the symbolic features using the refined knowledge base.\n",
    "# We will keep the same Random Forest model architecture and hyperparameters for comparison\n",
    "# to isolate the effect of the symbolic knowledge refinement.\n",
    "\n",
    "# Get the list of all unique medical conditions again (should be the same)\n",
    "all_conditions = list(le_condition.classes_)\n",
    "\n",
    "# Apply the function to generate symbolic features using the REFINED knowledge base\n",
    "symbolic_features_series_refined = df_combined['symptoms_medical'].apply(\n",
    "    lambda x: generate_symbolic_features(x, refined_medical_knowledge_base, all_conditions)\n",
    ")\n",
    "\n",
    "# Convert the Series of arrays into a 2D NumPy array\n",
    "symbolic_features_array_refined = np.vstack(symbolic_features_series_refined.values)\n",
    "\n",
    "# Select the numerical features (age) again\n",
    "numerical_features = df_combined[['age_medical']].values\n",
    "\n",
    "# Combine the TF-IDF features, REFINED symbolic features, and numerical features\n",
    "# X (TF-IDF dense) should be available from previous steps\n",
    "X_combined_neuro_symbolic_refined = np.hstack((X_dense, symbolic_features_array_refined, numerical_features))\n",
    "\n",
    "\n",
    "# Step 5: Re-train the updated model on the combined neuro-symbolic features (with refined symbolic features).\n",
    "# Split the refined combined data for training and testing\n",
    "X_train_ns_refined, X_test_ns_refined, y_train_ns_refined, y_test_ns_refined = train_test_split(\n",
    "    X_combined_neuro_symbolic_refined, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Re-instantiate the Random Forest model (or reuse the previous instance if preferred, but creating new is cleaner)\n",
    "rf_model_ns_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "print(\"\\nStarting Random Forest Model training on REFINED combined neuro-symbolic features...\")\n",
    "rf_model_ns_refined.fit(X_train_ns_refined, y_train_ns_refined)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Step 6: Re-evaluate the refined model's performance.\n",
    "y_pred_ns_refined = rf_model_ns_refined.predict(X_test_ns_refined)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_ns_refined = accuracy_score(y_test_ns_refined, y_pred_ns_refined)\n",
    "print(f\"\\nRandom Forest Model Accuracy (REFINED Neuro-Symbolic Features): {accuracy_ns_refined * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (REFINED Neuro-Symbolic Features):\")\n",
    "print(classification_report(y_test_ns_refined, y_pred_ns_refined, target_names=le_condition.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_ns_refined = confusion_matrix(y_test_ns_refined, y_pred_ns_refined)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_ns_refined, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Random Forest - REFINED Neuro-Symbolic Features)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score for Macro and Weighted averages\n",
    "macro_precision_ns_refined, macro_recall_ns_refined, macro_f1_ns_refined, _ = precision_recall_fscore_support(y_test_ns_refined, y_pred_ns_refined, average=\"macro\")\n",
    "weighted_precision_ns_refined, weighted_recall_ns_refined, weighted_f1_ns_refined, _ = precision_recall_fscore_support(y_test_ns_refined, y_pred_ns_refined, average=\"weighted\")\n",
    "\n",
    "# Display Macro and Weighted Average Metrics\n",
    "print(\"\\nMacro Average Metrics (REFINED Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {macro_precision_ns_refined:.2f}, Recall: {macro_recall_ns_refined:.2f}, F1 Score: {macro_f1_ns_refined:.2f}\")\n",
    "\n",
    "print(\"\\nWeighted Average Metrics (REFINED Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {weighted_precision_ns_refined:.2f}, Recall: {weighted_recall_ns_refined:.2f}, F1 Score: {weighted_f1_ns_refined:.2f}\")\n",
    "\n",
    "# Step 7: Compare the results of the refined model to the previous neuro-symbolic model.\n",
    "print(\"\\n--- Performance Comparison: Original vs. Refined Neuro-Symbolic ---\")\n",
    "print(f\"Original Neuro-Symbolic Accuracy: {accuracy_ns * 100:.2f}%\")\n",
    "print(f\"Refined Neuro-Symbolic Accuracy:  {accuracy_ns_refined * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nOriginal Neuro-Symbolic Macro F1:  {macro_f1_ns:.2f}\")\n",
    "print(f\"Refined Neuro-Symbolic Macro F1:   {macro_f1_ns_refined:.2f}\")\n",
    "\n",
    "print(\"\\nOriginal Neuro-Symbolic Weighted F1: {weighted_f1_ns:.2f}\")\n",
    "print(f\"Refined Neuro-Symbolic Weighted F1:  {weighted_f1_ns_refined:.2f}\")\n",
    "\n",
    "# You can also visually compare the classification reports and confusion matrices printed above.\n",
    "print(\"\\nCompare the Classification Reports and Confusion Matrices above to see class-specific changes.\")\n",
    "\n",
    "\"\"\"## Summary:\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "*   A simplified medical knowledge base was successfully created as a Python dictionary, mapping symptoms to associated medical conditions.\n",
    "*   Symbolic features were generated by counting symptom occurrences from patient notes based on this knowledge base.\n",
    "*   These symbolic features were combined with TF-IDF features from clinical notes and numerical age data to form a comprehensive neuro-symbolic feature set.\n",
    "*   A Random Forest classifier trained on the initial neuro-symbolic features achieved an accuracy of 94.50%, outperforming models trained on TF-IDF only (89.00%) and TF-IDF + Age (89.50%).\n",
    "*   Analysis of the initial neuro-symbolic model's performance showed high precision and recall for conditions like 'Ulcer' (1.00 F1-score), 'Diabetes' (1.00 recall), and 'Hypertension' (1.00 recall), suggesting that the symbolic features effectively leveraged specific symptom-disease links.\n",
    "*   Classes like 'Asthma' (0.56 recall) and 'Heart Disease' (0.59 recall) showed areas for improvement in the initial neuro-symbolic model.\n",
    "*   The symbolic knowledge base was refined by adding symptoms ('tightness in chest', 'difficulty breathing' for Asthma; 'palpitations', 'dizziness' for Heart Disease) to target the classes with lower performance.\n",
    "*   Retraining the Random Forest model with the refined symbolic features resulted in an overall accuracy of 94.50%, which was very similar to the original neuro-symbolic model's accuracy.\n",
    "*   Macro and weighted average F1-scores remained consistent between the original and refined neuro-symbolic models (both approximately 0.94).\n",
    "*   Specific class-level performance showed minor changes after refinement, but a significant improvement in recall for the targeted 'Asthma' and 'Heart Disease' classes was not observed in this specific refinement iteration.\n",
    "\n",
    "### Insights or Next Steps\n",
    "\n",
    "*   The integration of symbolic knowledge into a neuro-symbolic model significantly improved overall classification performance compared to purely text-based or combined text and numerical features.\n",
    "*   Further refinement of the symbolic knowledge base, potentially incorporating symptom weights, negation handling, or more nuanced medical relationships, could lead to further improvements, especially for specific medical conditions that currently have lower performance metrics.\n",
    "\n",
    "# Task\n",
    "Combine the provided dataset with emotional scores and clinical notes/symptoms to retrieve the type of medical condition or disease. Utilize neuro-symbolic NLP techniques, incorporating other machine learning and deep learning models for comparison of accuracies.\n",
    "\n",
    "## Identify and represent symbolic knowledge\n",
    "\n",
    "### Subtask:\n",
    "Define and represent the relevant medical knowledge (e.g., symptom-disease relationships, medical concepts) in a structured format suitable for integration. This could involve creating a knowledge graph, a rule base, or a simple dictionary.\n",
    "\n",
    "**Reasoning**:\n",
    "The subtask is to define and represent the relevant medical knowledge in a structured format. Creating and populating a Python dictionary with symptom-disease relationships directly addresses the instructions. Printing the dictionary allows for verification.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Create a Python dictionary to represent a simplified medical knowledge base\n",
    "# Step 2: Populate this knowledge base with a few relevant symptom-disease relationships based on your understanding or external resources.\n",
    "medical_knowledge_base = {\n",
    "    'fever': ['Infection', 'Influenza', 'Malaria', 'Typhoid'],\n",
    "    'cough': ['COPD', 'Asthma', 'Infection'],\n",
    "    'wheezing': ['COPD', 'Asthma'],\n",
    "    'shortness of breath': ['COPD', 'Asthma', 'Heart Disease'],\n",
    "    'chest pain': ['Heart Disease'],\n",
    "    'headache': ['Hypertension', 'Malaria', 'Typhoid'],\n",
    "    'nausea': ['Ulcer', 'Typhoid'],\n",
    "    'vomiting': ['Ulcer', 'Typhoid'],\n",
    "    'bloating': ['Ulcer'],\n",
    "    'swollen lymph nodes': ['HIV'],\n",
    "    'weight loss': ['HIV', 'Diabetes'],\n",
    "    'frequent urination': ['Diabetes'],\n",
    "    'increased thirst': ['Diabetes'],\n",
    "    'muscle pain': ['Malaria', 'Typhoid'],\n",
    "    'chills': ['Malaria', 'Typhoid', 'Infection'],\n",
    "    'fatigue': ['HIV', 'Diabetes', 'COPD', 'Asthma', 'Heart Disease', 'Unknown'],\n",
    "    'no symptoms': ['Unknown']\n",
    "}\n",
    "\n",
    "# Step 3: Print the created knowledge base\n",
    "print(\"Simplified Medical Knowledge Base:\")\n",
    "for symptom, conditions in medical_knowledge_base.items():\n",
    "    print(f\"- {symptom}: {conditions}\")\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "The symbolic knowledge base has been defined. Now, integrate this knowledge base into the feature engineering process by creating new features based on the symptom-disease relationships for each patient's symptoms and combine them with the existing features.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Assuming 'df_combined' is available from previous steps and contains the merged data\n",
    "# Assuming 'medical_knowledge_base' is available from the previous step\n",
    "\n",
    "# Ensure df_combined is properly preprocessed for symptoms\n",
    "df_combined['symptoms_medical'] = df_combined['symptoms_medical'].fillna('no symptoms')\n",
    "df_combined['symptoms_medical'] = df_combined['symptoms_medical'].apply(lambda x: ' '.join(str(x).split(',')))\n",
    "\n",
    "# Re-vectorize the symptoms column using TF-IDF on the updated df_combined\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "X = tfidf_vectorizer.fit_transform(df_combined['symptoms_medical'])\n",
    "\n",
    "# Re-encode the target variable (medical conditions)\n",
    "le_condition = LabelEncoder()\n",
    "y = le_condition.fit_transform(df_combined['medical_condition_medical'].fillna(\"Unknown\"))\n",
    "\n",
    "# Get the list of all unique medical conditions from the target variable\n",
    "all_conditions = list(le_condition.classes_)\n",
    "\n",
    "\n",
    "# Function to Generate Symbolic Features based on the defined knowledge base\n",
    "def generate_symbolic_features(symptoms_text, knowledge_base, all_possible_conditions):\n",
    "    \"\"\"\n",
    "    Generates symbolic features based on the presence of symptoms related to each condition\n",
    "    in the knowledge base.\n",
    "\n",
    "    Args:\n",
    "        symptoms_text (str): The cleaned symptoms text for a single patient.\n",
    "        knowledge_base (dict): The medical knowledge base mapping symptoms to conditions.\n",
    "        all_possible_conditions (list): A list of all possible medical conditions.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of symbolic features, where each element\n",
    "                       represents a count or binary indicator related to a specific condition.\n",
    "    \"\"\"\n",
    "    # Initialize feature vector with zeros for all conditions\n",
    "    # We'll use counts of relevant symptoms for each condition\n",
    "    symbolic_feature_counts = {condition: 0 for condition in all_possible_conditions}\n",
    "\n",
    "    # Split the symptoms text into individual symptom terms\n",
    "    individual_symptom_terms = symptoms_text.split()\n",
    "\n",
    "    # Iterate through the individual symptom terms for the patient\n",
    "    for term in individual_symptom_terms:\n",
    "        # Iterate through the symptoms in the knowledge base\n",
    "        for kb_symptom, associated_conditions in knowledge_base.items():\n",
    "            # Simple check if the symptom term matches a key in the knowledge base\n",
    "            # More sophisticated matching (fuzzy, stemming, concept linking) could be used here\n",
    "            if term == kb_symptom:\n",
    "                # If a match is found, increment the count for the associated conditions\n",
    "                for condition in associated_conditions:\n",
    "                     # Ensure the condition is one of our target conditions\n",
    "                    if condition in symbolic_feature_counts:\n",
    "                        symbolic_feature_counts[condition] += 1\n",
    "\n",
    "    # Convert the dictionary of counts to a list/array in the same order as all_possible_conditions\n",
    "    feature_vector = [symbolic_feature_counts[condition] for condition in all_possible_conditions]\n",
    "\n",
    "    return np.array(feature_vector)\n",
    "\n",
    "\n",
    "# Apply the function to your DataFrame to generate symbolic features\n",
    "# This will create a Series where each element is a NumPy array (the feature vector for a row)\n",
    "symbolic_features_series = df_combined['symptoms_medical'].apply(\n",
    "    lambda x: generate_symbolic_features(x, medical_knowledge_base, all_conditions)\n",
    ")\n",
    "\n",
    "# Convert the Series of arrays into a 2D NumPy array\n",
    "symbolic_features_array = np.vstack(symbolic_features_series.values)\n",
    "\n",
    "# Select the numerical features (e.g., age)\n",
    "# Based on previous steps, 'age_medical' is available in df_combined\n",
    "numerical_features = df_combined[['age_medical']].values\n",
    "\n",
    "\n",
    "# Combine the TF-IDF features, symbolic features, and numerical features\n",
    "# Convert sparse TF-IDF to dense before stacking\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Concatenate the dense TF-IDF array, symbolic features array, and numerical features array\n",
    "X_combined_neuro_symbolic = np.hstack((X_dense, symbolic_features_array, numerical_features))\n",
    "\n",
    "\n",
    "# Verify the shape of the combined feature array\n",
    "print(\"Shape of TF-IDF features (dense):\", X_dense.shape)\n",
    "print(\"Shape of Symbolic features:\", symbolic_features_array.shape)\n",
    "print(\"Shape of Numerical features:\", numerical_features.shape)\n",
    "print(\"Shape of combined (Neuro-Symbolic) features:\", X_combined_neuro_symbolic.shape)\n",
    "\n",
    "# Split the combined data for training and testing\n",
    "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(\n",
    "    X_combined_neuro_symbolic, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nData splitting complete for neuro-symbolic approach.\")\n",
    "print(\"Shape of X_train_ns:\", X_train_ns.shape)\n",
    "print(\"Shape of X_test_ns:\", X_test_ns.shape)\n",
    "print(\"Shape of y_train_ns:\", y_train_ns.shape)\n",
    "print(\"Shape of y_test_ns:\", y_test_ns.shape)\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "Train a classification model on the combined neuro-symbolic features and evaluate its performance.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Choose and instantiate a classification model (Random Forest)\n",
    "# Using the same model as trained on just TF-IDF + Age for comparison\n",
    "rf_model_ns = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Train the model on the combined neuro-symbolic training data\n",
    "print(\"Starting Random Forest Model training on combined neuro-symbolic features...\")\n",
    "rf_model_ns.fit(X_train_ns, y_train_ns)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Step 3: Evaluate the Model on the test set\n",
    "y_pred_ns = rf_model_ns.predict(X_test_ns)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_ns = accuracy_score(y_test_ns, y_pred_ns)\n",
    "print(f\"\\nRandom Forest Model Accuracy (Neuro-Symbolic Features): {accuracy_ns * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Neuro-Symbolic Features):\")\n",
    "# Ensure le_condition is available from previous steps for target_names\n",
    "print(classification_report(y_test_ns, y_pred_ns, target_names=le_condition.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_ns = confusion_matrix(y_test_ns, y_pred_ns)\n",
    "plt.figure(figsize=(10, 7))\n",
    "# Ensure le_condition is available from previous steps for xticklabels and yticklabels\n",
    "sns.heatmap(conf_matrix_ns, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Random Forest - Neuro-Symbolic Features)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score for Macro and Weighted averages\n",
    "macro_precision_ns, macro_recall_ns, macro_f1_ns, _ = precision_recall_fscore_support(y_test_ns, y_pred_ns, average=\"macro\")\n",
    "weighted_precision_ns, weighted_recall_ns, weighted_f1_ns, _ = precision_recall_fscore_support(y_test_ns, y_pred_ns, average=\"weighted\")\n",
    "\n",
    "# Display Macro and Weighted Average Metrics\n",
    "print(\"\\nMacro Average Metrics (Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {macro_precision_ns:.2f}, Recall: {macro_recall_ns:.2f}, F1 Score: {macro_f1_ns:.2f}\")\n",
    "\n",
    "print(\"\\nWeighted Average Metrics (Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {weighted_precision_ns:.2f}, Recall: {weighted_recall_ns:.2f}, F1 Score: {weighted_f1_ns:.2f}\")\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "Compare the performance metrics of the neuro-symbolic model with previous models, analyze the confusion matrices and classification reports, and discuss the impact of symbolic knowledge on predictions based on the knowledge base.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Compare overall accuracy\n",
    "print(\"--- Performance Comparison ---\")\n",
    "print(f\"Accuracy (Neuro-Symbolic Features): {accuracy_ns * 100:.2f}%\")\n",
    "\n",
    "# Assume 'accuracy' from cell 422f61fa is the model trained on TF-IDF + Age\n",
    "try:\n",
    "    print(f\"Accuracy (TF-IDF + Age Features): {accuracy * 100:.2f}%\")\n",
    "except NameError:\n",
    "    print(\"Accuracy for TF-IDF + Age features not available from previous runs.\")\n",
    "\n",
    "# Assume 'accuracy' from cell QMUEVD39SK3c is the Random Forest model trained on TF-IDF only\n",
    "# Note: This is a different Random Forest model instance, but provides a baseline\n",
    "try:\n",
    "    # Need to re-run the RF TF-IDF only cell to get its accuracy variable name\n",
    "    # As the variable name might be overwritten in later cells\n",
    "    # For now, we'll just print a placeholder or try to access the variable if we know its name\n",
    "    # Based on the output of QMUEVD39SK3c, the variable was also named 'accuracy'\n",
    "    # This is ambiguous, so we'll refer to the printed output\n",
    "    print(\"\\nRefer to previous cell outputs for Accuracy (TF-IDF only Random Forest): 89.00%\") # Hardcoded based on previous output\n",
    "except NameError:\n",
    "    print(\"Accuracy for TF-IDF only Random Forest not directly accessible.\")\n",
    "\n",
    "\n",
    "# Step 2 & 3: Analyze Confusion Matrices and Classification Reports\n",
    "print(\"\\n--- Analysis of Confusion Matrices and Classification Reports ---\")\n",
    "print(\"Comparing Classification Report (Neuro-Symbolic) vs (TF-IDF + Age):\")\n",
    "\n",
    "# Re-print classification report for TF-IDF + Age for easy comparison\n",
    "# Assuming the output from cell 422f61fa is available above this cell's output\n",
    "print(\"\\nClassification Report (TF-IDF + Age Features):\")\n",
    "# Need to re-calculate or re-print the report from the previous run if not already visible\n",
    "# Assuming the report from cell 422f61fa is visible in the output above.\n",
    "# If not, you would need to re-calculate it here using y_test and y_pred from that model.\n",
    "\n",
    "print(\"\\nClassification Report (Neuro-Symbolic Features):\")\n",
    "print(classification_report(y_test_ns, y_pred_ns, target_names=le_condition.classes_))\n",
    "\n",
    "\n",
    "print(\"\\nObserving changes in Confusion Matrices:\")\n",
    "print(\"Compare the Confusion Matrix (Random Forest - Neuro-Symbolic Features) shown above\")\n",
    "print(\"with the Confusion Matrix (Random Forest - Combined Features) from the previous run.\")\n",
    "print(\"Look for changes in diagonal values (True Positives) and off-diagonal values (False Positives/Negatives) for each class.\")\n",
    "\n",
    "# Step 4: Discuss the impact of symbolic knowledge\n",
    "print(\"\\n--- Impact of Symbolic Knowledge ---\")\n",
    "print(\"The symbolic features added to the model are counts of symptoms related to each medical condition based on the 'medical_knowledge_base'.\")\n",
    "print(\"These features provide the model with explicit, structured information about symptom-disease associations.\")\n",
    "print(\"Let's consider some examples based on the knowledge base and potential performance changes:\")\n",
    "\n",
    "print(\"\\nExample 1: Ulcer\")\n",
    "print(f\"Symptoms in KB for Ulcer: {medical_knowledge_base.get('bloating', []) + medical_knowledge_base.get('nausea', []) + medical_knowledge_base.get('vomiting', [])}\")\n",
    "print(\"If a patient's notes contain 'bloating', 'nausea', and 'vomiting', the symbolic feature for 'Ulcer' will have a high count.\")\n",
    "print(\"This strong, specific association in the KB likely helps the model correctly identify Ulcer cases, potentially leading to high precision and recall for this class.\")\n",
    "# Look at the confusion matrices - check if Ulcer had high true positives and low false positives/negatives in both models, and if NS is better.\n",
    "\n",
    "print(\"\\nExample 2: HIV\")\n",
    "print(f\"Symptoms in KB for HIV: {medical_knowledge_base.get('swollen lymph nodes', []) + medical_knowledge_base.get('weight loss', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(\"Swollen lymph nodes and weight loss are relatively specific symptoms for HIV in this simplified KB.\")\n",
    "print(\"The symbolic features for HIV would increase when these symptoms are present, potentially improving the model's ability to distinguish HIV from other conditions.\")\n",
    "# Check HIV's metrics and confusion matrix entries.\n",
    "\n",
    "print(\"\\nExample 3: Conditions with overlapping symptoms (e.g., COPD, Asthma, Infection)\")\n",
    "print(f\"Symptoms in KB for COPD: {medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('wheezing', []) + medical_knowledge_base.get('shortness of breath', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(f\"Symptoms in KB for Asthma: {medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('wheezing', []) + medical_knowledge_base.get('shortness of breath', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(f\"Symptoms in KB for Infection: {medical_knowledge_base.get('fever', []) + medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('chills', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(\"Since these conditions share symptoms like cough and fatigue in the KB, the symbolic features might not provide as much discriminative power as for conditions with more unique symptom profiles in the KB.\")\n",
    "print(\"Performance improvements for these classes might be less pronounced, or the model might still struggle to differentiate between them.\")\n",
    "# Examine confusion matrix entries between these classes (e.g., predicted COPD vs True Asthma).\n",
    "\n",
    "print(\"\\nOverall, the symbolic features likely act as a form of 'prior knowledge' or 'attention mechanism', guiding the model to pay more attention to symptoms that are medically relevant to specific conditions according to the knowledge base.\")\n",
    "print(\"This helps the model leverage established medical associations beyond just learning patterns from symptom term co-occurrences in the text data alone.\")\n",
    "print(\"Conditions with clear and relatively unique symptom definitions in the knowledge base are likely to see the most significant benefit from the inclusion of these symbolic features.\")\n",
    "\n",
    "# Step 5: Summarize the analysis (will be done in a markdown cell after this code block executes)\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "Summarize the analysis of the neuro-symbolic model's performance and the impact of symbolic knowledge as requested in the final step of the subtask.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Step 5: Summarize the analysis in a markdown cell.\n",
    "# This will be a markdown cell following this code block.\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "Provide a summary of the analysis of the neuro-symbolic model's performance and the impact of the incorporated symbolic knowledge, as requested in the final instruction of the subtask.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is a placeholder cell to satisfy the response format requirements.\n",
    "# The actual summary will be in the following markdown cell.\n",
    "print(\"Proceeding to summary.\")\n",
    "\n",
    "\"\"\"## Extract symbolic features\n",
    "\n",
    "### Subtask:\n",
    "Develop a method to extract symbolic features from the clinical notes and symptoms based on the defined symbolic knowledge.\n",
    "\n",
    "## Combine neural and symbolic features\n",
    "\n",
    "### Subtask:\n",
    "Integrate the extracted symbolic features with the neural features (e.g., TF-IDF features).\n",
    "\n",
    "**Reasoning**:\n",
    "The current subtask is to integrate the extracted symbolic features with the neural features (TF-IDF). This involves ensuring all necessary features (TF-IDF, symbolic, numerical) are available, converting sparse matrices to dense where needed, and concatenating them. The previous steps already generated the symbolic features and numerical features, and the TF-IDF features (`X`) were also generated in a prior step. The code in the previous history step already performed this integration, so I will execute that code block to ensure the `X_combined_neuro_symbolic` variable is available in the current runtime.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df_combined is available from previous steps and contains\n",
    "# 'symptoms_medical', 'age_medical', and 'medical_condition_medical'\n",
    "# Assuming medical_knowledge_base and le_condition are also available\n",
    "\n",
    "# Ensure df_combined is properly preprocessed for symptoms\n",
    "df_combined['symptoms_medical'] = df_combined['symptoms_medical'].fillna('no symptoms')\n",
    "df_combined['symptoms_medical'] = df_combined['symptoms_medical'].apply(lambda x: ' '.join(str(x).split(',')))\n",
    "\n",
    "# Re-vectorize the symptoms column using TF-IDF on the updated df_combined\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "X = tfidf_vectorizer.fit_transform(df_combined['symptoms_medical'])\n",
    "\n",
    "# Re-encode the target variable (medical conditions)\n",
    "le_condition = LabelEncoder()\n",
    "y = le_condition.fit_transform(df_combined['medical_condition_medical'].fillna(\"Unknown\"))\n",
    "\n",
    "# Get the list of all unique medical conditions from the target variable\n",
    "all_conditions = list(le_condition.classes_)\n",
    "\n",
    "\n",
    "# Function to Generate Symbolic Features based on the defined knowledge base\n",
    "def generate_symbolic_features(symptoms_text, knowledge_base, all_possible_conditions):\n",
    "    \"\"\"\n",
    "    Generates symbolic features based on the presence of symptoms related to each condition\n",
    "    in the knowledge base.\n",
    "\n",
    "    Args:\n",
    "        symptoms_text (str): The cleaned symptoms text for a single patient.\n",
    "        knowledge_base (dict): The medical knowledge base mapping symptoms to conditions.\n",
    "        all_possible_conditions (list): A list of all possible medical conditions.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of symbolic features, where each element\n",
    "                       represents a count or binary indicator related to a specific condition.\n",
    "    \"\"\"\n",
    "    # Initialize feature vector with zeros for all conditions\n",
    "    # We'll use counts of relevant symptoms for each condition\n",
    "    symbolic_feature_counts = {condition: 0 for condition in all_possible_conditions}\n",
    "\n",
    "    # Split the symptoms text into individual symptom terms\n",
    "    individual_symptom_terms = symptoms_text.split()\n",
    "\n",
    "    # Iterate through the individual symptom terms for the patient\n",
    "    for term in individual_symptom_terms:\n",
    "        # Iterate through the symptoms in the knowledge base\n",
    "        for kb_symptom, associated_conditions in knowledge_base.items():\n",
    "            # Simple check if the symptom term matches a key in the knowledge base\n",
    "            # More sophisticated matching (fuzzy, stemming, concept linking) could be used here\n",
    "            if term == kb_symptom:\n",
    "                # If a match is found, increment the count for the associated conditions\n",
    "                for condition in associated_conditions:\n",
    "                     # Ensure the condition is one of our target conditions\n",
    "                    if condition in symbolic_feature_counts:\n",
    "                        symbolic_feature_counts[condition] += 1\n",
    "\n",
    "    # Convert the dictionary of counts to a list/array in the same order as all_possible_conditions\n",
    "    feature_vector = [symbolic_feature_counts[condition] for condition in all_possible_conditions]\n",
    "\n",
    "    return np.array(feature_vector)\n",
    "\n",
    "\n",
    "# Apply the function to your DataFrame to generate symbolic features\n",
    "# This will create a Series where each element is a NumPy array (the feature vector for a row)\n",
    "symbolic_features_series = df_combined['symptoms_medical'].apply(\n",
    "    lambda x: generate_symbolic_features(x, medical_knowledge_base, all_conditions)\n",
    ")\n",
    "\n",
    "# Convert the Series of arrays into a 2D NumPy array\n",
    "symbolic_features_array = np.vstack(symbolic_features_series.values)\n",
    "\n",
    "# Select the numerical features (e.g., age)\n",
    "# Based on previous steps, 'age_medical' is available in df_combined\n",
    "numerical_features = df_combined[['age_medical']].values\n",
    "\n",
    "\n",
    "# Combine the TF-IDF features, symbolic features, and numerical features\n",
    "# Convert sparse TF-IDF to dense before stacking\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Concatenate the dense TF-IDF array, symbolic features array, and numerical features array\n",
    "X_combined_neuro_symbolic = np.hstack((X_dense, symbolic_features_array, numerical_features))\n",
    "\n",
    "\n",
    "# Verify the shape of the combined feature array\n",
    "print(\"Shape of TF-IDF features (dense):\", X_dense.shape)\n",
    "print(\"Shape of Symbolic features:\", symbolic_features_array.shape)\n",
    "print(\"Shape of Numerical features:\", numerical_features.shape)\n",
    "print(\"Shape of combined (Neuro-Symbolic) features:\", X_combined_neuro_symbolic.shape)\n",
    "\n",
    "# Split the combined data for training and testing\n",
    "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(\n",
    "    X_combined_neuro_symbolic, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nData splitting complete for neuro-symbolic approach.\")\n",
    "print(\"Shape of X_train_ns:\", X_train_ns.shape)\n",
    "print(\"Shape of X_test_ns:\", X_test_ns.shape)\n",
    "print(\"Shape of y_train_ns:\", y_train_ns.shape)\n",
    "print(\"Shape of y_test_ns:\", y_test_ns.shape)\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "The integration of features is complete. The next logical step according to the overall task is to train a model on the combined neuro-symbolic feature set. I will train a classification model (Random Forest as used previously) on the combined features and then evaluate its performance. This combines the \"Model training\" and \"Model evaluation\" steps of the overall task.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Choose and instantiate a classification model (Random Forest)\n",
    "# Using the same model as trained on just TF-IDF + Age for comparison\n",
    "rf_model_ns = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Train the model on the combined neuro-symbolic training data\n",
    "print(\"Starting Random Forest Model training on combined neuro-symbolic features...\")\n",
    "rf_model_ns.fit(X_train_ns, y_train_ns)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Step 3: Evaluate the Model on the test set\n",
    "y_pred_ns = rf_model_ns.predict(X_test_ns)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_ns = accuracy_score(y_test_ns, y_pred_ns)\n",
    "print(f\"\\nRandom Forest Model Accuracy (Neuro-Symbolic Features): {accuracy_ns * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Neuro-Symbolic Features):\")\n",
    "# Ensure le_condition is available from previous steps for target_names\n",
    "print(classification_report(y_test_ns, y_pred_ns, target_names=le_condition.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_ns = confusion_matrix(y_test_ns, y_pred_ns)\n",
    "plt.figure(figsize=(10, 7))\n",
    "# Ensure le_condition is available from previous steps for xticklabels and yticklabels\n",
    "sns.heatmap(conf_matrix_ns, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Random Forest - Neuro-Symbolic Features)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score for Macro and Weighted averages\n",
    "macro_precision_ns, macro_recall_ns, macro_f1_ns, _ = precision_recall_fscore_support(y_test_ns, y_pred_ns, average=\"macro\")\n",
    "weighted_precision_ns, weighted_recall_ns, weighted_f1_ns, _ = precision_recall_fscore_support(y_test_ns, y_pred_ns, average=\"weighted\")\n",
    "\n",
    "# Display Macro and Weighted Average Metrics\n",
    "print(\"\\nMacro Average Metrics (Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {macro_precision_ns:.2f}, Recall: {macro_recall_ns:.2f}, F1 Score: {macro_f1_ns:.2f}\")\n",
    "\n",
    "print(\"\\nWeighted Average Metrics (Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {weighted_precision_ns:.2f}, Recall: {weighted_recall_ns:.2f}, F1 Score: {weighted_f1_ns:.2f}\")\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "The model has been trained and evaluated. The next step is to analyze and interpret the results, focusing on how the symbolic knowledge influenced the predictions. This aligns with the overall task of incorporating neuro-symbolic NLP techniques and analyzing their impact. I will execute the code block that performs this analysis and comparison.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Compare overall accuracy\n",
    "print(\"--- Performance Comparison ---\")\n",
    "print(f\"Accuracy (Neuro-Symbolic Features): {accuracy_ns * 100:.2f}%\")\n",
    "\n",
    "# Assume 'accuracy' from cell 422f61fa is the model trained on TF-IDF + Age\n",
    "try:\n",
    "    print(f\"Accuracy (TF-IDF + Age Features): {accuracy * 100:.2f}%\")\n",
    "except NameError:\n",
    "    print(\"Accuracy for TF-IDF + Age features not available from previous runs.\")\n",
    "\n",
    "# Assume 'accuracy' from cell QMUEVD39SK3c is the Random Forest model trained on TF-IDF only\n",
    "# Note: This is a different Random Forest model instance, but provides a baseline\n",
    "try:\n",
    "    # Need to re-run the RF TF-IDF only cell to get its accuracy variable name\n",
    "    # As the variable name might be overwritten in later cells\n",
    "    # For now, we'll just print a placeholder or try to access the variable if we know its name\n",
    "    # Based on the output of QMUEVD39SK3c, the variable was also named 'accuracy'\n",
    "    # This is ambiguous, so we'll refer to the printed output\n",
    "    print(\"\\nRefer to previous cell outputs for Accuracy (TF-IDF only Random Forest): 89.00%\") # Hardcoded based on previous output\n",
    "except NameError:\n",
    "    print(\"Accuracy for TF-IDF only Random Forest not directly accessible.\")\n",
    "\n",
    "\n",
    "# Step 2 & 3: Analyze Confusion Matrices and Classification Reports\n",
    "print(\"\\n--- Analysis of Confusion Matrices and Classification Reports ---\")\n",
    "print(\"Comparing Classification Report (Neuro-Symbolic) vs (TF-IDF + Age):\")\n",
    "\n",
    "# Re-print classification report for TF-IDF + Age for easy comparison\n",
    "# Assuming the output from cell 422f61fa is available above this cell's output\n",
    "print(\"\\nClassification Report (TF-IDF + Age Features):\")\n",
    "# Need to re-calculate or re-print the report from the previous run if not already visible\n",
    "# Assuming the report from cell 422f61fa is visible in the output above.\n",
    "# If not, you would need to re-calculate it here using y_test and y_pred from that model.\n",
    "\n",
    "print(\"\\nClassification Report (Neuro-Symbolic Features):\")\n",
    "print(classification_report(y_test_ns, y_pred_ns, target_names=le_condition.classes_))\n",
    "\n",
    "\n",
    "print(\"\\nObserving changes in Confusion Matrices:\")\n",
    "print(\"Compare the Confusion Matrix (Random Forest - Neuro-Symbolic Features) shown above\")\n",
    "print(\"with the Confusion Matrix (Random Forest - Combined Features) from the previous run.\")\n",
    "print(\"Look for changes in diagonal values (True Positives) and off-diagonal values (False Positives/Negatives) for each class.\")\n",
    "\n",
    "# Step 4: Discuss the impact of symbolic knowledge\n",
    "print(\"\\n--- Impact of Symbolic Knowledge ---\")\n",
    "print(\"The symbolic features added to the model are counts of symptoms related to each medical condition based on the 'medical_knowledge_base'.\")\n",
    "print(\"These features provide the model with explicit, structured information about symptom-disease associations.\")\n",
    "print(\"Let's consider some examples based on the knowledge base and potential performance changes:\")\n",
    "\n",
    "print(\"\\nExample 1: Ulcer\")\n",
    "print(f\"Symptoms in KB for Ulcer: {medical_knowledge_base.get('bloating', []) + medical_knowledge_base.get('nausea', []) + medical_knowledge_base.get('vomiting', [])}\")\n",
    "print(\"If a patient's notes contain 'bloating', 'nausea', and 'vomiting', the symbolic feature for 'Ulcer' will have a high count.\")\n",
    "print(\"This strong, specific association in the KB likely helps the model correctly identify Ulcer cases, potentially leading to high precision and recall for this class.\")\n",
    "# Look at the confusion matrices - check if Ulcer had high true positives and low false positives/negatives in both models, and if NS is better.\n",
    "\n",
    "print(\"\\nExample 2: HIV\")\n",
    "print(f\"Symptoms in KB for HIV: {medical_knowledge_base.get('swollen lymph nodes', []) + medical_knowledge_base.get('weight loss', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(\"Swollen lymph nodes and weight loss are relatively specific symptoms for HIV in this simplified KB.\")\n",
    "print(\"The symbolic features for HIV would increase when these symptoms are present, potentially improving the model's ability to distinguish HIV from other conditions.\")\n",
    "# Check HIV's metrics and confusion matrix entries.\n",
    "\n",
    "print(\"\\nExample 3: Conditions with overlapping symptoms (e.g., COPD, Asthma, Infection)\")\n",
    "print(f\"Symptoms in KB for COPD: {medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('wheezing', []) + medical_knowledge_base.get('shortness of breath', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(f\"Symptoms in KB for Asthma: {medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('wheezing', []) + medical_knowledge_base.get('shortness of breath', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(f\"Symptoms in KB for Infection: {medical_knowledge_base.get('fever', []) + medical_knowledge_base.get('cough', []) + medical_knowledge_base.get('chills', []) + medical_knowledge_base.get('fatigue', [])}\")\n",
    "print(\"Since these conditions share symptoms like cough and fatigue in the KB, the symbolic features might not provide as much discriminative power as for conditions with more unique symptom profiles in the KB.\")\n",
    "print(\"Performance improvements for these classes might be less pronounced, or the model might still struggle to differentiate between them.\")\n",
    "# Examine confusion matrix entries between these classes (e.g., predicted COPD vs True Asthma).\n",
    "\n",
    "print(\"\\nOverall, the symbolic features likely act as a form of 'prior knowledge' or 'attention mechanism', guiding the model to pay more attention to symptoms that are medically relevant to specific conditions according to the knowledge base.\")\n",
    "print(\"This helps the model leverage established medical associations beyond just learning patterns from symptom term co-occurrences in the text data alone.\")\n",
    "print(\"Conditions with clear and relatively unique symptom definitions in the knowledge base are likely to see the most significant benefit from the inclusion of these symbolic features.\")\n",
    "\n",
    "# Step 5: Summarize the analysis (will be done in a markdown cell after this code block executes)\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "The analysis of the initial neuro-symbolic model is complete. The next logical step is to refine the symbolic knowledge and/or model architecture based on the analysis and retrain/re-evaluate the model. The code in the previous history step already performs this refinement and evaluation, so I will execute that code block to perform this step of the subtask.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Review the classification report and confusion matrix from the neuro-symbolic model's evaluation.\n",
    "# The classification report and confusion matrix were printed in the previous execution of cell 3c2e6158.\n",
    "# Observing the output, some classes like 'Asthma' and 'Heart Disease' still have lower recall and F1-scores\n",
    "# compared to others, suggesting potential areas for improvement.\n",
    "\n",
    "print(\"Reviewing previous Classification Report (Neuro-Symbolic Features):\")\n",
    "# The report is available in the previous cell's output. Let's print it again for clarity.\n",
    "print(classification_report(y_test_ns, y_pred_ns, target_names=le_condition.classes_))\n",
    "\n",
    "print(\"\\nReviewing previous Confusion Matrix (Neuro-Symbolic Features):\")\n",
    "# The confusion matrix plot is available in the previous cell's output. We can visually inspect it.\n",
    "# For analysis purposes, we can print the matrix values if needed:\n",
    "# print(conf_matrix_ns)\n",
    "\n",
    "# Based on the report, 'Asthma' (recall 0.56) and 'Heart Disease' (recall 0.59) are candidates for refinement.\n",
    "\n",
    "# Step 2 & 3: Examine the medical_knowledge_base and consider refinement.\n",
    "# Current KB entries for these conditions:\n",
    "# 'Asthma': ['cough', 'wheezing', 'shortness of breath', 'fatigue']\n",
    "# 'Heart Disease': ['shortness of breath', 'chest pain', 'fatigue']\n",
    "\n",
    "# Refinement Idea: Add more specific or common symptoms for Asthma and Heart Disease\n",
    "# (This is a simplified example; real refinement needs medical expertise and data analysis)\n",
    "refined_medical_knowledge_base = medical_knowledge_base.copy()\n",
    "# Add 'tightness in chest' and 'difficulty breathing' for Asthma\n",
    "refined_medical_knowledge_base['tightness in chest'] = ['Asthma']\n",
    "refined_medical_knowledge_base['difficulty breathing'] = ['Asthma', 'COPD', 'Heart Disease'] # Overlap with other conditions\n",
    "# Add 'palpitations' and 'dizziness' for Heart Disease\n",
    "refined_medical_knowledge_base['palpitations'] = ['Heart Disease']\n",
    "refined_medical_knowledge_base['dizziness'] = ['Heart Disease', 'Hypertension', 'Unknown'] # Overlap\n",
    "\n",
    "print(\"\\nRefined Medical Knowledge Base (Partial View):\")\n",
    "print(f\"- tightness in chest: {refined_medical_knowledge_base.get('tightness in chest')}\")\n",
    "print(f\"- difficulty breathing: {refined_medical_knowledge_base.get('difficulty breathing')}\")\n",
    "print(f\"- palpitations: {refined_medical_knowledge_base.get('palpitations')}\")\n",
    "print(f\"- dizziness: {refined_medical_knowledge_base.get('dizziness')}\")\n",
    "\n",
    "\n",
    "# Step 4: Implement the chosen refinements.\n",
    "# We will regenerate the symbolic features using the refined knowledge base.\n",
    "# We will keep the same Random Forest model architecture and hyperparameters for comparison\n",
    "# to isolate the effect of the symbolic knowledge refinement.\n",
    "\n",
    "# Get the list of all unique medical conditions again (should be the same)\n",
    "all_conditions = list(le_condition.classes_)\n",
    "\n",
    "# Apply the function to generate symbolic features using the REFINED knowledge base\n",
    "symbolic_features_series_refined = df_combined['symptoms_medical'].apply(\n",
    "    lambda x: generate_symbolic_features(x, refined_medical_knowledge_base, all_conditions)\n",
    ")\n",
    "\n",
    "# Convert the Series of arrays into a 2D NumPy array\n",
    "symbolic_features_array_refined = np.vstack(symbolic_features_series_refined.values)\n",
    "\n",
    "# Select the numerical features (age) again\n",
    "numerical_features = df_combined[['age_medical']].values\n",
    "\n",
    "# Combine the TF-IDF features, REFINED symbolic features, and numerical features\n",
    "# X (TF-IDF dense) should be available from previous steps\n",
    "X_combined_neuro_symbolic_refined = np.hstack((X_dense, symbolic_features_array_refined, numerical_features))\n",
    "\n",
    "\n",
    "# Step 5: Re-train the updated model on the combined neuro-symbolic features (with refined symbolic features).\n",
    "# Split the refined combined data for training and testing\n",
    "X_train_ns_refined, X_test_ns_refined, y_train_ns_refined, y_test_ns_refined = train_test_split(\n",
    "    X_combined_neuro_symbolic_refined, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Re-instantiate the Random Forest model (or reuse the previous instance if preferred, but creating new is cleaner)\n",
    "rf_model_ns_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "print(\"\\nStarting Random Forest Model training on REFINED combined neuro-symbolic features...\")\n",
    "rf_model_ns_refined.fit(X_train_ns_refined, y_train_ns_refined)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Step 6: Re-evaluate the refined model's performance.\n",
    "y_pred_ns_refined = rf_model_ns_refined.predict(X_test_ns_refined)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_ns_refined = accuracy_score(y_test_ns_refined, y_pred_ns_refined)\n",
    "print(f\"\\nRandom Forest Model Accuracy (REFINED Neuro-Symbolic Features): {accuracy_ns_refined * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (REFINED Neuro-Symbolic Features):\")\n",
    "print(classification_report(y_test_ns_refined, y_pred_ns_refined, target_names=le_condition.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_ns_refined = confusion_matrix(y_test_ns_refined, y_pred_ns_refined)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_ns_refined, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Random Forest - REFINED Neuro-Symbolic Features)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score for Macro and Weighted averages\n",
    "macro_precision_ns_refined, macro_recall_ns_refined, macro_f1_ns_refined, _ = precision_recall_fscore_support(y_test_ns_refined, y_pred_ns_refined, average=\"macro\")\n",
    "weighted_precision_ns_refined, weighted_recall_ns_refined, weighted_f1_ns_refined, _ = precision_recall_fscore_support(y_test_ns_refined, y_pred_ns_refined, average=\"weighted\")\n",
    "\n",
    "# Display Macro and Weighted Average Metrics\n",
    "print(\"\\nMacro Average Metrics (REFINED Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {macro_precision_ns_refined:.2f}, Recall: {macro_recall_ns_refined:.2f}, F1 Score: {macro_f1_ns_refined:.2f}\")\n",
    "\n",
    "print(\"\\nWeighted Average Metrics (REFINED Neuro-Symbolic Features):\")\n",
    "print(f\"Precision: {weighted_precision_ns_refined:.2f}, Recall: {weighted_recall_ns_refined:.2f}, F1 Score: {weighted_f1_ns_refined:.2f}\")\n",
    "\n",
    "# Step 7: Compare the results of the refined model to the previous neuro-symbolic model.\n",
    "print(\"\\n--- Performance Comparison: Original vs. Refined Neuro-Symbolic ---\")\n",
    "print(f\"Original Neuro-Symbolic Accuracy: {accuracy_ns * 100:.2f}%\")\n",
    "print(f\"Refined Neuro-Symbolic Accuracy:  {accuracy_ns_refined * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nOriginal Neuro-Symbolic Macro F1:  {macro_f1_ns:.2f}\")\n",
    "print(f\"Refined Neuro-Symbolic Macro F1:   {macro_f1_ns_refined:.2f}\")\n",
    "\n",
    "print(\"\\nOriginal Neuro-Symbolic Weighted F1: {weighted_f1_ns:.2f}\")\n",
    "print(f\"Refined Neuro-Symbolic Weighted F1:  {weighted_f1_ns_refined:.2f}\")\n",
    "\n",
    "# You can also visually compare the classification reports and confusion matrices printed above.\n",
    "print(\"\\nCompare the Classification Reports and Confusion Matrices above to see class-specific changes.\")\n",
    "\n",
    "\"\"\"**Reasoning**:\n",
    "The refinement and re-evaluation of the neuro-symbolic model are complete. The final step of the subtask is to summarize the analysis and interpret how the symbolic knowledge influenced the predictions, including the impact of the refinement. I will provide this summary in a markdown cell.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# No code is needed for the summary, it will be a markdown cell.\n",
    "\n",
    "\"\"\"## Train and evaluate multiple neuro-symbolic models\n",
    "\n",
    "### Subtask:\n",
    "Train several machine learning and deep learning models on the combined neural and symbolic features and evaluate their performance.\n",
    "\n",
    "**Reasoning**:\n",
    "Split the data, train Multinomial Naive Bayes, SVM, and Gradient Boosting models, evaluate each, and display their confusion matrices as per the instructions for the current subtask.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Split the combined neuro-symbolic feature set and the target variable\n",
    "# Using the refined features from the previous step\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined_neuro_symbolic_refined, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 2: Initialize and train a Multinomial Naive Bayes model\n",
    "mnb = MultinomialNB()\n",
    "print(\"Starting Multinomial Naive Bayes training...\")\n",
    "# MultinomialNB expects non-negative integer features.\n",
    "# Our symbolic features are counts, which are non-negative integers.\n",
    "# TF-IDF features can be floats but are typically non-negative.\n",
    "# Age is a non-negative integer.\n",
    "# This model might not be ideal for combined float (TF-IDF) and integer features.\n",
    "# However, we will proceed as requested.\n",
    "mnb.fit(X_train, y_train)\n",
    "print(\"Multinomial Naive Bayes training complete.\")\n",
    "\n",
    "# Step 3: Evaluate the Multinomial Naive Bayes model\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "print(f\"\\nMultinomial Naive Bayes Accuracy: {accuracy_mnb * 100:.2f}%\")\n",
    "print(\"\\nMultinomial Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_mnb, target_names=le_condition.classes_))\n",
    "\n",
    "# Store macro and weighted metrics for MNB\n",
    "macro_p_mnb, macro_r_mnb, macro_f1_mnb, _ = precision_recall_fscore_support(y_test, y_pred_mnb, average=\"macro\")\n",
    "weighted_p_mnb, weighted_r_mnb, weighted_f1_mnb, _ = precision_recall_fscore_support(y_test, y_pred_mnb, average=\"weighted\")\n",
    "\n",
    "# Step 8 (part 1): Confusion matrix for Multinomial Naive Bayes\n",
    "conf_matrix_mnb = confusion_matrix(y_test, y_pred_mnb)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_mnb, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Multinomial Naive Bayes)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 4: Initialize and train a Support Vector Machine (SVM) model\n",
    "# Using 'rbf' kernel as it often performs well. Setting probability=True for potential future use.\n",
    "svm_model = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "print(\"\\nStarting SVM training...\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "print(\"SVM training complete.\")\n",
    "\n",
    "# Step 5: Evaluate the SVM model\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"\\nSVM Accuracy: {accuracy_svm * 100:.2f}%\")\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=le_condition.classes_))\n",
    "\n",
    "# Store macro and weighted metrics for SVM\n",
    "macro_p_svm, macro_r_svm, macro_f1_svm, _ = precision_recall_fscore_support(y_test, y_pred_svm, average=\"macro\")\n",
    "weighted_p_svm, weighted_r_svm, weighted_f1_svm, _ = precision_recall_fscore_support(y_test, y_pred_svm, average=\"weighted\")\n",
    "\n",
    "# Step 8 (part 2): Confusion matrix for SVM\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_svm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (SVM)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 6: Initialize and train a Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "print(\"\\nStarting Gradient Boosting training...\")\n",
    "gb_model.fit(X_train, y_train)\n",
    "print(\"Gradient Boosting training complete.\")\n",
    "\n",
    "# Step 7: Evaluate the Gradient Boosting model\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"\\nGradient Boosting Accuracy: {accuracy_gb * 100:.2f}%\")\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb, target_names=le_condition.classes_))\n",
    "\n",
    "# Store macro and weighted metrics for GB\n",
    "macro_p_gb, macro_r_gb, macro_f1_gb, _ = precision_recall_fscore_support(y_test, y_pred_gb, average=\"macro\")\n",
    "weighted_p_gb, weighted_r_gb, weighted_f1_gb, _ = precision_recall_fscore_support(y_test, y_pred_gb, average=\"weighted\")\n",
    "\n",
    "# Step 8 (part 3): Confusion matrix for Gradient Boosting\n",
    "conf_matrix_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_gb, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_condition.classes_, yticklabels=le_condition.classes_)\n",
    "plt.title(\"Confusion Matrix (Gradient Boosting)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"## Compare model performance\n",
    "\n",
    "### Subtask:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
